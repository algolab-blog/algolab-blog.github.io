<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Bot on ALGO GEEKS</title>
    <link>http://blog.algolab.jp/tags/bot/</link>
    <description>Recent content in Bot on ALGO GEEKS</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ja</language>
    <lastBuildDate>Sat, 30 Jul 2016 15:50:23 +0900</lastBuildDate>
    <atom:link href="http://blog.algolab.jp/tags/bot/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Seq2Seqモデルを用いたチャットボット作成 〜英会話のサンプルを動かす〜</title>
      <link>http://blog.algolab.jp/post/2016/07/30/seq2seq-chatbot/</link>
      <pubDate>Sat, 30 Jul 2016 15:50:23 +0900</pubDate>
      
      <guid>http://blog.algolab.jp/post/2016/07/30/seq2seq-chatbot/</guid>
      <description>

&lt;p&gt;最近、チャットボットが話題となっていますが、自然な会話を成り立たせること、は大きな課題の一つです。&lt;br /&gt;
ここでは、Deep Learningの一種である、Seq2Seqモデルを用いて、チャットボットを動作させてみます。&lt;br /&gt;
ゴールとして、英語を学習させ、実際に会話を行ってみることを目指します。&lt;/p&gt;

&lt;h2 id=&#34;seq2seq-sequence-to-sequence-モデルとは&#34;&gt;Seq2Seq (Sequence to Sequence) モデルとは&lt;/h2&gt;

&lt;figure&gt;
  &lt;img src=&#34;http://blog.algolab.jp/images//post/2016/07/30/seq2seq-chatbot//seq2seq.png&#34;/&gt;
  
&lt;/figure&gt;


&lt;p&gt;平たく言うと、ある文字列から、次の文字列を予測するモデルのことです。&lt;br /&gt;
上記の図では、「ABC」を入力として、「WXYZ」を出力 (予測) しています。&lt;/p&gt;

&lt;p&gt;Seq2Seqモデルの対話タスクへの応用を試みたのがGoogleで、2015年に下記の論文を発表しています。&lt;/p&gt;

&lt;p&gt;A Neural Conversational Model&lt;br /&gt;
&lt;a href=&#34;http://arxiv.org/abs/1506.05869&#34;&gt;http://arxiv.org/abs/1506.05869&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;これまでの対話モデルは、ドメインを絞り (飛行機を予約するなど) 、手でルールを記載する必要があったが、Seq2Seqモデルを用いて対話データを学習させることで、自然な応答ができるようになった、と論文内で述べています。&lt;/p&gt;

&lt;h2 id=&#34;実装例&#34;&gt;実装例&lt;/h2&gt;

&lt;p&gt;Seq2Seqモデルを用いたチャットボットの実装は、色々な人が公開しています。&lt;br /&gt;
&lt;a href=&#34;https://github.com/nicolas-ivanov/seq2seq_chatbot_links&#34;&gt;https://github.com/nicolas-ivanov/seq2seq_chatbot_links&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;今回は、実装例の中で、最も良い結果が出たとされている、以下のリポジトリのコードを動作させてみます。
&lt;a href=&#34;https://github.com/macournoyer/neuralconvo&#34;&gt;https://github.com/macournoyer/neuralconvo&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;環境構築&#34;&gt;環境構築&lt;/h2&gt;

&lt;p&gt;基本的には下記の手順で進めます。&lt;br /&gt;
&lt;a href=&#34;https://github.com/macournoyer/neuralconvo#installing&#34;&gt;https://github.com/macournoyer/neuralconvo#installing&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;ソースコードのダウンロード&#34;&gt;ソースコードのダウンロード&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;git clone https://github.com/macournoyer/neuralconvo.git
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;torchのインストール&#34;&gt;Torchのインストール&lt;/h3&gt;

&lt;p&gt;公式に従って、インストールします。&lt;br /&gt;
&lt;a href=&#34;http://torch.ch/docs/getting-started.html&#34;&gt;http://torch.ch/docs/getting-started.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;環境によって叩くコマンドが違うため、詳細は上記リンクをご参照ください。&lt;br /&gt;
下記は、Ubuntu + zshでの例です。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;git clone https://github.com/torch/distro.git ~/torch --recursive
cd ~/torch; bash install-deps;
./install.sh
source ~/.zshrc
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;luaライブラリのインストール&#34;&gt;Luaライブラリのインストール&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;luarocks install nn
luarocks install rnn
luarocks install penlight
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;GPUを用いて学習を行うので、下記もインストールします。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;luarocks install cutorch
luarocks install cunn
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;データセットの準備&#34;&gt;データセットの準備&lt;/h3&gt;

&lt;p&gt;データセットは、下記で公開されている映画の台詞コーパスを用います。&lt;br /&gt;
&lt;a href=&#34;http://www.mpi-sws.org/~cristian/Cornell_Movie-Dialogs_Corpus.html&#34;&gt;http://www.mpi-sws.org/~cristian/Cornell_Movie-Dialogs_Corpus.html&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;cd neuralconvo/data
wget http://www.mpi-sws.org/~cristian/data/cornell_movie_dialogs_corpus.zip
unzip cornell_movie_dialogs_corpus.zip
mv cornell\ movie-dialogs\ corpus cornell_movie_dialogs
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;学習&#34;&gt;学習&lt;/h2&gt;

&lt;p&gt;準備が整ったら学習をしてみます。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;th train.lua --cuda --dataset 50000 --hiddenSize 1000
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;学習には AWSのg2.2xlargeインスタンスを用い、学習時間は4日弱でした。&lt;br /&gt;
なお、エラー率の推移は下記となりました。&lt;/p&gt;

&lt;figure&gt;
  &lt;img src=&#34;http://blog.algolab.jp/images//post/2016/07/30/seq2seq-chatbot//error.png&#34;/&gt;
  
&lt;/figure&gt;


&lt;h2 id=&#34;テスト&#34;&gt;テスト&lt;/h2&gt;

&lt;p&gt;学習したモデルを用いて実際に会話をしてみました。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;th eval.lua
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;you&amp;gt;&lt;/strong&gt; Hello?&lt;br /&gt;
&lt;strong&gt;neuralconvo&amp;gt;&lt;/strong&gt; Hello, darling.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;you&amp;gt;&lt;/strong&gt; How are you?&lt;br /&gt;
&lt;strong&gt;neuralconvo&amp;gt;&lt;/strong&gt; I&amp;rsquo;m fine.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;you&amp;gt;&lt;/strong&gt; Are you a machine?&lt;br /&gt;
&lt;strong&gt;neuralconvo&amp;gt;&lt;/strong&gt; No, i don&amp;rsquo;t.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;you&amp;gt;&lt;/strong&gt; Are you intelligent?&lt;br /&gt;
&lt;strong&gt;neuralconvo&amp;gt;&lt;/strong&gt; No.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;それっぽい会話は成り立つようです。哲学的な質問をしてみます。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;you&amp;gt;&lt;/strong&gt; What is the purpose of living?&lt;br /&gt;
&lt;strong&gt;neuralconvo&amp;gt;&lt;/strong&gt; I&amp;rsquo;ve been watching over the phone thing&amp;hellip;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;うーん。深い&amp;hellip;!?&lt;/p&gt;

&lt;h2 id=&#34;評価&#34;&gt;評価&lt;/h2&gt;

&lt;p&gt;上記のように会話として成立するものもあれば、全く成り立たないケースもありました。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;you&amp;gt;&lt;/strong&gt; What color is the sky?&lt;br /&gt;
&lt;strong&gt;neuralconvo&amp;gt;&lt;/strong&gt; The other plate is currently in new york, in some kind of a tree in a decent, don&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;知識が足りないのはデータセットの不足で、文章として成立していないのは学習不足、といったところでしょうか。&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>