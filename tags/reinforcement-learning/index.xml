<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Reinforcement Learning on ALGO GEEKS</title>
    <link>http://blog.algolab.jp/tags/reinforcement-learning/</link>
    <description>Recent content in Reinforcement Learning on ALGO GEEKS</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ja</language>
    <lastBuildDate>Mon, 01 Aug 2016 22:06:25 +0900</lastBuildDate>
    <atom:link href="http://blog.algolab.jp/tags/reinforcement-learning/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>超シンプルにDQN (Deep Q Network) を実装してみる 〜導入編〜</title>
      <link>http://blog.algolab.jp/post/2016/08/01/tf-dqn-simple-1/</link>
      <pubDate>Mon, 01 Aug 2016 22:06:25 +0900</pubDate>
      
      <guid>http://blog.algolab.jp/post/2016/08/01/tf-dqn-simple-1/</guid>
      <description>

&lt;p&gt;みなさん、DQNしてますか？&lt;br /&gt;
DQNについては、下記の記事によくまとめられており、実装してみようとした方も多いのではないでしょうか。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://qiita.com/Ugo-Nama/items/08c6a5f6a571335972d5&#34;&gt;DQNの生い立ち　＋　Deep Q-NetworkをChainerで書いた&lt;/a&gt;&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://qiita.com/icoxfog417/items/242439ecd1a477ece312&#34;&gt;ゼロからDeepまで学ぶ強化学習&lt;/a&gt;&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;しかし、いざ自力で動作させてみようとすると、こんな問題にぶち当たると思います。&lt;/p&gt;

&lt;p&gt;「学習時間なげえ。。。」&lt;/p&gt;

&lt;p&gt;DQNに限らず、ディープラーニングのモデルを学習させようとすると、平気で数日以上かかります。&lt;br /&gt;
そして、学習させたモデルが期待通りの動作をしなかったとしたら、もう投げ出したくなってしまいます。&lt;br /&gt;
(よくある話です)&lt;/p&gt;

&lt;p&gt;なので、筆者が新しいモデルを一から実装する際には、なるべく単純なモデル、データから始めるようにしています。&lt;/p&gt;

&lt;p&gt;ここでは、超シンプルなDQNを実装し、動作させてみることにします。&lt;br /&gt;
早速いってみましょう。CPUで3分もあれば学習が終わります！&lt;/p&gt;

&lt;h2 id=&#34;まずは動かしてみよう&#34;&gt;まずは動かしてみよう&lt;/h2&gt;

&lt;figure&gt;
  &lt;img src=&#34;http://blog.algolab.jp/images//post/2016/08/01/tf-dqn-simple-1//demo-catch_ball.gif&#34;/&gt;
  
&lt;/figure&gt;


&lt;h3 id=&#34;概要&#34;&gt;概要&lt;/h3&gt;

&lt;p&gt;具体的には、上図のように上から落ちてくるボールをキャッチする、というタスクを学習させます。&lt;br /&gt;
TensorFlowで実装しており、ソースコードは下記に公開しています。&lt;br /&gt;
&lt;a href=&#34;https://github.com/algolab-inc/tf-dqn-simple&#34;&gt;https://github.com/algolab-inc/tf-dqn-simple&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;環境構築&#34;&gt;環境構築&lt;/h3&gt;

&lt;p&gt;はじめにソースコードをダウンロードします。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;git clone https://github.com/algolab-inc/tf-dqn-simple.git
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;次に、動作のためにTensorFlowとMatplotlibが必要なので、インストールします。&lt;/p&gt;

&lt;p&gt;Tensorflowについては下記リンクを参照のうえインストールを行ってください。&lt;br /&gt;
&lt;a href=&#34;https://www.tensorflow.org/versions/master/get_started/os_setup.html&#34;&gt;https://www.tensorflow.org/versions/master/get_started/os_setup.html&lt;/a&gt;&lt;br /&gt;
(2016/08/01現在、Python3.5.2 + Tensorflow0.9.0での動作を確認しています)&lt;/p&gt;

&lt;p&gt;Matolotlibはpipでインストールします。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;pip install matplotlib
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;学習&#34;&gt;学習&lt;/h3&gt;

&lt;p&gt;環境が整ったら、ソースコードのディレクトリに移動して、train.pyを叩くと学習が始まります。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;cd tf-dqn-simple
python train.py
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;下記のようなログが出ていれば、正しく学習が行われています。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;EPOCH: 000/999 | WIN: 001 | LOSS: 0.0068 | Q_MAX: 0.0008&lt;br /&gt;
EPOCH: 001/999 | WIN: 002 | LOSS: 0.0447 | Q_MAX: 0.0013&lt;br /&gt;
&amp;hellip;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;数分ほどで学習が終わったかと思います。&lt;br /&gt;
では学習したモデルでテストしてみましょう。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;python test.py
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;WIN: 001/001 (100.0%)&lt;br /&gt;
WIN: 002/002 (100.0%)&lt;br /&gt;
&amp;hellip;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;キャッチボールのアニメーションとともに、上記のようなログが出れば成功です。&lt;br /&gt;
きちんと動作しましたでしょうか？&lt;br /&gt;
学習がうまくいっていれば、おそらく100%でキャッチできていると思います。&lt;/p&gt;

&lt;p&gt;次回は、実装編についてお届けします。&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>