<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Tensorflow on ALGO GEEKS</title>
    <link>http://blog.algolab.jp/tags/tensorflow/</link>
    <description>Recent content in Tensorflow on ALGO GEEKS</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ja</language>
    <lastBuildDate>Fri, 11 Nov 2016 18:47:53 +0900</lastBuildDate>
    <atom:link href="http://blog.algolab.jp/tags/tensorflow/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>TensorFlowで画風変換を試す</title>
      <link>http://blog.algolab.jp/post/2016/11/11/neuralart/</link>
      <pubDate>Fri, 11 Nov 2016 18:47:53 +0900</pubDate>
      
      <guid>http://blog.algolab.jp/post/2016/11/11/neuralart/</guid>
      <description>

&lt;figure&gt;
  &lt;img src=&#34;http://blog.algolab.jp/images//post/2016/11/11/neuralart//animation.gif&#34;/&gt;
  
&lt;/figure&gt;


&lt;p&gt;TensorFlowを用いて画風変換を試してみました。上記画像は学習過程となります。&lt;br /&gt;
GitHubで「neuralart」と検索すると実装例がいくつか出てきますので、そのうちの一つを動作させてみます。&lt;br /&gt;
&lt;a href=&#34;https://github.com/ckmarkoh/neuralart_tensorflow&#34;&gt;https://github.com/ckmarkoh/neuralart_tensorflow&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;なお、環境構築については下記の記事をご参照ください。Python2系での動作を確認しています。&lt;br /&gt;
&lt;a href=&#34;{{ref &amp;quot;post/2016/08/21/pyenv-anaconda-ubuntu.md&amp;quot;}}&#34;&gt;【随時更新】pyenv + Anaconda (Ubuntu 16.04 LTS) で機械学習のPython開発環境をオールインワンで整える&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;ソースコードをダウンロード&#34;&gt;ソースコードをダウンロード&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;$ git clone https://github.com/ckmarkoh/neuralart_tensorflow.git
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;訓練済み画像認識モデルをダウンロード&#34;&gt;訓練済み画像認識モデルをダウンロード&lt;/h2&gt;

&lt;p&gt;下記URLからVGG-19モデルをダウンロードし、&lt;code&gt;neuralart_tensorflow&lt;/code&gt;直下に配置します。
&lt;a href=&#34;https://drive.google.com/file/d/0B8QJdgMvQDrVU2cyZjFKU1RrLUU/view&#34;&gt;https://drive.google.com/file/d/0B8QJdgMvQDrVU2cyZjFKU1RrLUU/view&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;画風変換&#34;&gt;画風変換&lt;/h2&gt;

&lt;p&gt;以下で画風変換のイテレーションが始まります。元画像とスタイル画像は下記の通りとなります。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;$ python main.py
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;元画像
&lt;figure&gt;
  &lt;img src=&#34;http://blog.algolab.jp/images//post/2016/11/11/neuralart//Taipei101.jpg&#34;/&gt;
  
&lt;/figure&gt;
&lt;/p&gt;

&lt;p&gt;スタイル画像
&lt;figure&gt;
  &lt;img src=&#34;http://blog.algolab.jp/images//post/2016/11/11/neuralart//StarryNight.jpg&#34;/&gt;
  
&lt;/figure&gt;
&lt;/p&gt;

&lt;p&gt;結果は&lt;code&gt;results&lt;/code&gt;フォルダに格納されていきます。&lt;br /&gt;
なお、筆者の環境では、CPUマシンで100イテレーションあたり1時間弱かかりました。&lt;/p&gt;

&lt;h2 id=&#34;学習過程を可視化&#34;&gt;学習過程を可視化&lt;/h2&gt;

&lt;p&gt;900イテレーションまでの結果画像をImageMagickを用いてアニメーションGIFにしてみます。&lt;br /&gt;
（冒頭で紹介した画像となります）&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;$ cd results
$ convert -delay 50 -loop 0 0*00.png animation.gif
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;論文&#34;&gt;論文&lt;/h2&gt;

&lt;p&gt;画風変換の元となる論文はこちらです。&lt;br /&gt;
&lt;a href=&#34;https://arxiv.org/abs/1508.06576&#34;&gt;A Neural Algorithm of Artistic Style&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>超シンプルにTensorFlowでDQN (Deep Q Network) を実装してみる 〜導入編〜</title>
      <link>http://blog.algolab.jp/post/2016/08/01/tf-dqn-simple-1/</link>
      <pubDate>Mon, 01 Aug 2016 22:06:25 +0900</pubDate>
      
      <guid>http://blog.algolab.jp/post/2016/08/01/tf-dqn-simple-1/</guid>
      <description>

&lt;p&gt;みなさん、DQNしてますか？&lt;br /&gt;
DQNについては、下記の記事によくまとめられており、実装してみようとした方も多いのではないでしょうか。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://qiita.com/Ugo-Nama/items/08c6a5f6a571335972d5&#34;&gt;DQNの生い立ち　＋　Deep Q-NetworkをChainerで書いた&lt;/a&gt;&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://qiita.com/icoxfog417/items/242439ecd1a477ece312&#34;&gt;ゼロからDeepまで学ぶ強化学習&lt;/a&gt;&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;しかし、いざ自力で動作させてみようとすると、こんな問題にぶち当たると思います。&lt;/p&gt;

&lt;p&gt;「学習時間なげえ。。。」&lt;/p&gt;

&lt;p&gt;DQNに限らず、ディープラーニングのモデルを学習させようとすると、平気で数日以上かかります。&lt;br /&gt;
そして、学習させたモデルが期待通りの動作をしなかったとしたら、もう投げ出したくなってしまいます。&lt;br /&gt;
(よくある話です)&lt;/p&gt;

&lt;p&gt;なので、筆者が新しいモデルを一から実装する際には、なるべく単純なモデル、データから始めるようにしています。&lt;/p&gt;

&lt;p&gt;ここでは、超シンプルなDQNを実装し、動作させてみることにします。&lt;br /&gt;
早速いってみましょう。CPUで3分もあれば学習が終わります！&lt;/p&gt;

&lt;h2 id=&#34;まずは動かしてみよう&#34;&gt;まずは動かしてみよう&lt;/h2&gt;

&lt;figure&gt;
  &lt;img src=&#34;http://blog.algolab.jp/images//post/2016/08/01/tf-dqn-simple-1//demo-catch_ball.gif&#34;/&gt;
  
&lt;/figure&gt;


&lt;h3 id=&#34;概要&#34;&gt;概要&lt;/h3&gt;

&lt;p&gt;具体的には、上図のように上から落ちてくるボールをキャッチする、というゲームを学習させます。&lt;br /&gt;
TensorFlowで実装しており、ソースコードは下記に公開しています。&lt;br /&gt;
&lt;a href=&#34;https://github.com/algolab-inc/tf-dqn-simple&#34;&gt;https://github.com/algolab-inc/tf-dqn-simple&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;環境構築&#34;&gt;環境構築&lt;/h3&gt;

&lt;p&gt;はじめにソースコードをダウンロードします。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;$ git clone https://github.com/algolab-inc/tf-dqn-simple.git
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;次に、動作のためにTensorFlowとMatplotlibが必要なので、インストールします。&lt;/p&gt;

&lt;p&gt;Tensorflowについては下記リンクを参照のうえインストールを行ってください。&lt;br /&gt;
&lt;a href=&#34;https://www.tensorflow.org/versions/master/get_started/os_setup.html&#34;&gt;https://www.tensorflow.org/versions/master/get_started/os_setup.html&lt;/a&gt;&lt;br /&gt;
(2016/08/01現在、Python3.5.2 + Tensorflow0.9.0での動作を確認しています)&lt;/p&gt;

&lt;p&gt;Matolotlibはpipでインストールします。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;$ pip install matplotlib
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;学習&#34;&gt;学習&lt;/h3&gt;

&lt;p&gt;環境が整ったら、ソースコードのディレクトリに移動して、train.pyを叩くと学習が始まります。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;$ cd tf-dqn-simple
$ python train.py
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;下記のようなログが出ていれば、正しく学習が行われています。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;EPOCH: 000/999 | WIN: 001 | LOSS: 0.0068 | Q_MAX: 0.0008&lt;br /&gt;
EPOCH: 001/999 | WIN: 002 | LOSS: 0.0447 | Q_MAX: 0.0013&lt;br /&gt;
&amp;hellip;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;数分ほどで学習が終わったかと思います。&lt;br /&gt;
では学習したモデルでテストしてみましょう。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;$ python test.py
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;WIN: 001/001 (100.0%)&lt;br /&gt;
WIN: 002/002 (100.0%)&lt;br /&gt;
&amp;hellip;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;キャッチボールのアニメーションとともに、上記のようなログが出れば成功です。&lt;br /&gt;
きちんと動作しましたでしょうか？&lt;br /&gt;
学習がうまくいっていれば、おそらく100%でキャッチできていると思います。&lt;/p&gt;

&lt;p&gt;次回は、実装編についてお届けします。&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>