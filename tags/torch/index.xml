<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Torch on ALGO GEEKS</title>
    <link>http://blog.algolab.jp/tags/torch/</link>
    <description>Recent content in Torch on ALGO GEEKS</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ja</language>
    <lastBuildDate>Wed, 03 Aug 2016 17:12:34 +0900</lastBuildDate>
    <atom:link href="http://blog.algolab.jp/tags/torch/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>TorchをAWSのGPUインスタンス (Ubuntu 14.04) で動かす</title>
      <link>http://blog.algolab.jp/post/2016/08/03/torch-aws-gpu-ubuntu/</link>
      <pubDate>Wed, 03 Aug 2016 17:12:34 +0900</pubDate>
      
      <guid>http://blog.algolab.jp/post/2016/08/03/torch-aws-gpu-ubuntu/</guid>
      <description>

&lt;p&gt;TorchをAWSのGPUインスタンス (Ubuntu 14.04) で動かす手順をまとめます。&lt;br /&gt;
環境は以下の通りです。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Ubuntu Server 14.04 LTS&lt;/li&gt;
&lt;li&gt;CUDA7.5&lt;/li&gt;
&lt;li&gt;CuDNN v5&lt;/li&gt;
&lt;li&gt;Torch7&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;インスタンスを起動&#34;&gt;インスタンスを起動&lt;/h2&gt;

&lt;figure&gt;
  &lt;img src=&#34;http://blog.algolab.jp/images//post/2016/08/03/torch-aws-gpu-ubuntu//ubuntu.png&#34;/&gt;
  
&lt;/figure&gt;


&lt;p&gt;Ubuntu Server 14.04 LTS (HVM), SSD Volume Type - ami-2d39803a をベースに構築します。&lt;br /&gt;
インスタンスタイプはg2.2xlargeを用いました。&lt;br /&gt;
ストレージ容量はデフォルトの8GBでは不足するので、16GBとします。&lt;/p&gt;

&lt;figure&gt;
  &lt;img src=&#34;http://blog.algolab.jp/images//post/2016/08/03/torch-aws-gpu-ubuntu//storage.png&#34;/&gt;
  
&lt;/figure&gt;


&lt;h2 id=&#34;パッケージ更新&#34;&gt;パッケージ更新&lt;/h2&gt;

&lt;p&gt;インスタンスが起動したら、SSHでログインのうえ、まずパッケージを更新します。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;sudo apt-get update
sudo apt-get upgrade -y
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;cudaインストール&#34;&gt;CUDAインストール&lt;/h2&gt;

&lt;p&gt;CUDAのインストールはハマりどころが多いですが、先人の知恵にならって進めます。&lt;br /&gt;
&lt;a href=&#34;https://gist.github.com/erikbern/78ba519b97b440e10640&#34;&gt;https://gist.github.com/erikbern/78ba519b97b440e10640&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;既存のドライバ (Noveau) を無効にします。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;echo -e &amp;quot;blacklist nouveau\nblacklist lbm-nouveau\noptions nouveau modeset=0\nalias nouveau off\nalias lbm-nouveau off\n&amp;quot; | sudo tee /etc/modprobe.d/blacklist-nouveau.conf
echo options nouveau modeset=0 | sudo tee -a /etc/modprobe.d/nouveau-kms.conf
sudo update-initramfs -u
sudo reboot
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;必要なカーネルモジュールをインストールします。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;sudo apt-get install -y linux-image-extra-virtual
sudo reboot
sudo apt-get install -y linux-source linux-headers-`uname -r`
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;CUDA7.5をインストールします。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;wget http://developer.download.nvidia.com/compute/cuda/7.5/Prod/local_installers/cuda_7.5.18_linux.run
chmod +x cuda_7.5.18_linux.run
./cuda_7.5.18_linux.run -extract=`pwd`/nvidia_installers
cd nvidia_installers
sudo ./NVIDIA-Linux-x86_64-352.39.run
sudo modprobe nvidia
sudo ./cuda-linux64-rel-7.5.18-19867135.run
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;途中でシンボリックリンクを作成するか聞かれますが、yesを選択します。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;Would you like to create a symbolic link /usr/local/cuda pointing to /usr/local/cuda-7.5? ((y)es/(n)o/(a)bort) [ default is yes ]: y
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;CUDAのパスを環境変数に追加します。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;echo -e &amp;quot;export PATH=/usr/local/cuda/bin:\$PATH\nexport LD_LIBRARY_PATH=/usr/local/cuda/lib64:\$LD_LIBRARY_PATH&amp;quot; | tee -a ~/.bashrc
source ~/.bashrc
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;cudnnインストール&#34;&gt;CUDNNインストール&lt;/h2&gt;

&lt;p&gt;まず、下記のサイトからアカウントを登録します。&lt;br /&gt;
&lt;a href=&#34;https://developer.nvidia.com/cudnn&#34;&gt;https://developer.nvidia.com/cudnn&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;アカウント登録後、ダウンロードページから、cuDNN v5 Library for Linuxをダウンロードします。
&lt;figure&gt;
  &lt;img src=&#34;http://blog.algolab.jp/images//post/2016/08/03/torch-aws-gpu-ubuntu//cudnn.png&#34;/&gt;
  
&lt;/figure&gt;
&lt;/p&gt;

&lt;p&gt;ダウンロードしたファイルをサーバへ転送後、サーバ上で展開します。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;tar -xzf cudnn-7.5-linux-x64-v5.0-ga.tgz
sudo cp cuda/lib64/libcudnn* /usr/local/cuda-7.5/lib64
sudo cp cuda/include/cudnn.h /usr/local/cuda/include
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;torchインストール&#34;&gt;Torchインストール&lt;/h2&gt;

&lt;p&gt;公式に従って、インストールします。&lt;br /&gt;
&lt;a href=&#34;http://torch.ch/docs/getting-started.html&#34;&gt;http://torch.ch/docs/getting-started.html&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;sudo apt-get install -y git
git clone https://github.com/torch/distro.git ~/torch --recursive
cd ~/torch; bash install-deps;
./install.sh
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;環境変数を.bashrcに書き込むか聞かれますが、yesを選択します。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;Do you want to automatically prepend the Torch install location
to PATH and LD_LIBRARY_PATH in your /home/ubuntu/.bashrc? (yes/no)
[yes] &amp;gt;&amp;gt;&amp;gt; 
yes
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;環境変数を反映します。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;source ~/.bashrc
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;最後に、CUDAおよびcuDNNを使うためのLuaライブラリをインストールします。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;luarocks install cutorch
luarocks install cunn
luarocks install cunnx
luarocks install https://raw.githubusercontent.com/soumith/cudnn.torch/master/cudnn-scm-1.rockspec
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;以上で環境構築は完了です。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Seq2Seqモデルを用いたチャットボット作成 〜英会話のサンプルをTorchで動かす〜</title>
      <link>http://blog.algolab.jp/post/2016/07/30/seq2seq-chatbot/</link>
      <pubDate>Sat, 30 Jul 2016 15:50:23 +0900</pubDate>
      
      <guid>http://blog.algolab.jp/post/2016/07/30/seq2seq-chatbot/</guid>
      <description>

&lt;p&gt;最近、チャットボットが話題となっていますが、自然な会話を成り立たせること、は大きな課題の一つです。&lt;br /&gt;
ここでは、Deep Learningの一種である、Seq2Seqモデルを用いて、チャットボットを動作させてみます。&lt;br /&gt;
ゴールとして、英語を学習させ、実際に会話を行ってみることを目指します。&lt;/p&gt;

&lt;h2 id=&#34;seq2seq-sequence-to-sequence-モデルとは&#34;&gt;Seq2Seq (Sequence to Sequence) モデルとは&lt;/h2&gt;

&lt;figure&gt;
  &lt;img src=&#34;http://blog.algolab.jp/images//post/2016/07/30/seq2seq-chatbot//seq2seq.png&#34;/&gt;
  
&lt;/figure&gt;


&lt;p&gt;平たく言うと、ある文字列から、次の文字列を予測するモデルのことです。&lt;br /&gt;
上記の図では、「ABC」を入力として、「WXYZ」を出力 (予測) しています。&lt;/p&gt;

&lt;p&gt;Seq2Seqモデルの対話タスクへの応用を試みたのがGoogleで、2015年に下記の論文を発表しています。&lt;/p&gt;

&lt;p&gt;A Neural Conversational Model&lt;br /&gt;
&lt;a href=&#34;http://arxiv.org/abs/1506.05869&#34;&gt;http://arxiv.org/abs/1506.05869&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;これまでの対話モデルは、ドメインを絞り (飛行機を予約するなど) 、手でルールを記載する必要があったが、Seq2Seqモデルを用いて対話データを学習させることで、自然な応答ができるようになった、と論文内で述べています。&lt;/p&gt;

&lt;h2 id=&#34;実装例&#34;&gt;実装例&lt;/h2&gt;

&lt;p&gt;Seq2Seqモデルを用いたチャットボットの実装は、色々な人が公開しています。&lt;br /&gt;
&lt;a href=&#34;https://github.com/nicolas-ivanov/seq2seq_chatbot_links&#34;&gt;https://github.com/nicolas-ivanov/seq2seq_chatbot_links&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;今回は、実装例の中で、最も良い結果が出たとされている、以下のリポジトリのコードを動作させてみます。&lt;br /&gt;
&lt;a href=&#34;https://github.com/macournoyer/neuralconvo&#34;&gt;https://github.com/macournoyer/neuralconvo&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;環境構築&#34;&gt;環境構築&lt;/h2&gt;

&lt;p&gt;基本的には下記の手順で進めます。&lt;br /&gt;
&lt;a href=&#34;https://github.com/macournoyer/neuralconvo#installing&#34;&gt;https://github.com/macournoyer/neuralconvo#installing&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;筆者は下記の環境をベースに、追加で必要なLuaモジュールをインストール (更新) しました。&lt;br /&gt;
&lt;a href=&#34;http://blog.algolab.jp/post/2016/08/03/torch-aws-gpu-ubuntu/&#34;&gt;TorchをAWSのGPUインスタンス (Ubuntu 14.04) で動かす&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;luarocks install nn
luarocks install rnn
luarocks install penlight
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;データセットの準備&#34;&gt;データセットの準備&lt;/h3&gt;

&lt;p&gt;データセットは、下記で公開されている映画の台詞コーパスを用います。&lt;br /&gt;
&lt;a href=&#34;http://www.mpi-sws.org/~cristian/Cornell_Movie-Dialogs_Corpus.html&#34;&gt;http://www.mpi-sws.org/~cristian/Cornell_Movie-Dialogs_Corpus.html&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;git clone https://github.com/macournoyer/neuralconvo.git
cd neuralconvo/data
wget http://www.mpi-sws.org/~cristian/data/cornell_movie_dialogs_corpus.zip
unzip cornell_movie_dialogs_corpus.zip
mv cornell\ movie-dialogs\ corpus cornell_movie_dialogs
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;学習&#34;&gt;学習&lt;/h2&gt;

&lt;p&gt;準備が整ったら学習をしてみます。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;th train.lua --cuda --dataset 50000 --hiddenSize 1000
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;学習時間は4日弱で、エラー率の推移は下記となりました。&lt;/p&gt;

&lt;figure&gt;
  &lt;img src=&#34;http://blog.algolab.jp/images//post/2016/07/30/seq2seq-chatbot//error.png&#34;/&gt;
  
&lt;/figure&gt;


&lt;h2 id=&#34;会話してみる&#34;&gt;会話してみる&lt;/h2&gt;

&lt;p&gt;学習したモデルを用いて実際に会話をしてみました。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;th eval.lua
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;you&amp;gt;&lt;/strong&gt; Hello?&lt;br /&gt;
&lt;strong&gt;neuralconvo&amp;gt;&lt;/strong&gt; Hello, darling.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;you&amp;gt;&lt;/strong&gt; How are you?&lt;br /&gt;
&lt;strong&gt;neuralconvo&amp;gt;&lt;/strong&gt; I&amp;rsquo;m fine.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;you&amp;gt;&lt;/strong&gt; Are you a machine?&lt;br /&gt;
&lt;strong&gt;neuralconvo&amp;gt;&lt;/strong&gt; No, i don&amp;rsquo;t.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;you&amp;gt;&lt;/strong&gt; Are you intelligent?&lt;br /&gt;
&lt;strong&gt;neuralconvo&amp;gt;&lt;/strong&gt; No.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;それっぽい会話は成り立つようです。哲学的な質問をしてみます。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;you&amp;gt;&lt;/strong&gt; What is the purpose of living?&lt;br /&gt;
&lt;strong&gt;neuralconvo&amp;gt;&lt;/strong&gt; I&amp;rsquo;ve been watching over the phone thing&amp;hellip;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;うーん。深い&amp;hellip;!?&lt;/p&gt;

&lt;h2 id=&#34;会話が成り立たないケースもある&#34;&gt;会話が成り立たないケースもある&lt;/h2&gt;

&lt;p&gt;上記のように会話として成立するものもあれば、全く成り立たないケースもありました。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;you&amp;gt;&lt;/strong&gt; What color is the sky?&lt;br /&gt;
&lt;strong&gt;neuralconvo&amp;gt;&lt;/strong&gt; The other plate is currently in new york, in some kind of a tree in a decent, don&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;おわりに&#34;&gt;おわりに&lt;/h2&gt;

&lt;p&gt;実用的に使える精度か、という点では疑問符が残るものの、End-to-End で学習ができるというのは魅力的です。&lt;br /&gt;
いかに有用なデータセットを構築するか、が重要なポイントとなってきそうです。&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>