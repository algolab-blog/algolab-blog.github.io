<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>音声認識 on ALGO GEEKS</title>
    <link>http://blog.algolab.jp/tags/%E9%9F%B3%E5%A3%B0%E8%AA%8D%E8%AD%98/</link>
    <description>Recent content in 音声認識 on ALGO GEEKS</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ja</language>
    <lastBuildDate>Tue, 16 Aug 2016 19:34:57 +0900</lastBuildDate>
    <atom:link href="http://blog.algolab.jp/tags/%E9%9F%B3%E5%A3%B0%E8%AA%8D%E8%AD%98/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>iOSで音声認識 〜Speech Frameworkを試す〜</title>
      <link>http://blog.algolab.jp/post/2016/08/16/speech-framework/</link>
      <pubDate>Tue, 16 Aug 2016 19:34:57 +0900</pubDate>
      
      <guid>http://blog.algolab.jp/post/2016/08/16/speech-framework/</guid>
      <description>

&lt;p&gt;2016/08/16現在、まだβ版という位置づけですが、Apple謹製の音声認識エンジン (Speech Framework) が公開されています。今回は、下記のサンプルコードを動作させてみます。
&lt;a href=&#34;https://developer.apple.com/library/prerelease/content/samplecode/SpeakToMe/Introduction/Intro.html&#34;&gt;https://developer.apple.com/library/prerelease/content/samplecode/SpeakToMe/Introduction/Intro.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;動作を確認するにはXcode 8.0以降、iOS 10.0 以降が必要なので、環境を整えるところから始めます。&lt;/p&gt;

&lt;h2 id=&#34;apple-developer-program-へ登録&#34;&gt;Apple Developer Program へ登録&lt;/h2&gt;

&lt;p&gt;諸々インストールするためには、Developer登録が必須なので、以下より登録を行います。
&lt;a href=&#34;https://developer.apple.com/programs/jp/&#34;&gt;https://developer.apple.com/programs/jp/&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;xcode-8-betaをmacにインストール&#34;&gt;Xcode 8 betaをMacにインストール&lt;/h2&gt;

&lt;p&gt;Macから下記ページへアクセスし、Xcode 8 betaをダウンロード、インストールします。&lt;br /&gt;
&lt;a href=&#34;https://developer.apple.com/download/&#34;&gt;https://developer.apple.com/download/&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;ios-10-betaをiphone-にインストール&#34;&gt;iOS 10 betaをiPhone にインストール&lt;/h2&gt;

&lt;p&gt;iPhoneか下記ページへアクセスし、iOS 10 betaをダウンロード、インストールします。&lt;br /&gt;
&lt;a href=&#34;https://developer.apple.com/download/&#34;&gt;https://developer.apple.com/download/&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;サンプルコードをダウンロード&#34;&gt;サンプルコードをダウンロード&lt;/h2&gt;

&lt;p&gt;下記ページより、サンプルコードをダウンロードします。
&lt;a href=&#34;https://developer.apple.com/library/prerelease/content/samplecode/SpeakToMe/Introduction/Intro.html&#34;&gt;https://developer.apple.com/library/prerelease/content/samplecode/SpeakToMe/Introduction/Intro.html&lt;/a&gt;&lt;/p&gt;

&lt;figure&gt;
  &lt;img src=&#34;http://blog.algolab.jp/images//post/2016/08/16/speech-framework//speak_to_me.png&#34;/&gt;
  
&lt;/figure&gt;


&lt;h2 id=&#34;署名の確認&#34;&gt;署名の確認&lt;/h2&gt;

&lt;p&gt;サンプルコードを開き、&lt;code&gt;TARGETS -&amp;gt; General -&amp;gt; Signing&lt;/code&gt;にDeveloper登録を行っているTeamが選択されているか確認します。
(ここが正しく設定されていないと実機でのビルドに失敗します)&lt;/p&gt;

&lt;h2 id=&#34;日本語対応&#34;&gt;日本語対応&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;ViewController.swift&lt;/code&gt;の15行目、言語指定のコードを&lt;code&gt;en-US&lt;/code&gt;から&lt;code&gt;ja-JP&lt;/code&gt;に書き換えます。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-swift&#34;&gt;private let speechRecognizer = SFSpeechRecognizer(locale: Locale(identifier: &amp;quot;ja-JP&amp;quot;))!
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;認識精度を確認&#34;&gt;認識精度を確認&lt;/h2&gt;

&lt;p&gt;実機で動作させ、認識精度を確認してみます。まず、「吾輩は猫である」を認識させてみます。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;吾輩は猫である。名前はまだ無い。どこで生れたかとんと見当がつかぬ。何でも薄暗いじめじめした所でニャーニャー泣いていた事だけは記憶している。吾輩はここで始めて人間というものを見た。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;認識結果がこちら。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;吾輩は猫である。名前はまだない。どこで生まれたかとんと見当がつかん。何でも薄暗いじめじめした所でニャンニャン泣いていた事だけは記憶している。吾輩はここで始めて人間というものを見た。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;ほぼ正解と言っていい認識精度です。ここまで精度が高いとは正直驚きです。&lt;/p&gt;

&lt;h2 id=&#34;次回予告&#34;&gt;次回予告&lt;/h2&gt;

&lt;p&gt;次回はサンプルコードの中身を追ってみようと思います。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Amazon Echoを6,000円で自作する 〜Raspberry Pi 3 &#43; Alexa Voice Services (AVS)〜</title>
      <link>http://blog.algolab.jp/post/2016/08/11/raspberry-pi-alexa/</link>
      <pubDate>Thu, 11 Aug 2016 19:08:44 +0900</pubDate>
      
      <guid>http://blog.algolab.jp/post/2016/08/11/raspberry-pi-alexa/</guid>
      <description>

&lt;p&gt;&lt;a href=&#34;http://blog.algolab.jp/post/2016/07/29/mary-meeker-2016/&#34;&gt;音声は新しいパラダイムシフトになる 〜2016年度版メアリー・ミーカー氏レポートまとめ〜&lt;/a&gt; でも触れたように、次世代デバイスとしてAmazon Echoは注目するべき存在です。&lt;/p&gt;

&lt;p&gt;しかしながら、日本では技適の関係で未だ使用できません。&lt;br /&gt;
ただ、Alexa Voice Services (AVS) というものが公開されており、Amazon Echoを様々なデバイスで動作させることが可能です。&lt;/p&gt;

&lt;p&gt;今回は、Raspberry Pi 3からAVSを利用できるようにしました。&lt;br /&gt;
セットアップについては下記にある通りですが、低予算での最低限の手順をまとめてみます。
&lt;a href=&#34;https://github.com/amzn/alexa-avs-raspberry-pi&#34;&gt;https://github.com/amzn/alexa-avs-raspberry-pi&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;完成したもの&#34;&gt;完成したもの&lt;/h2&gt;

&lt;p&gt;いきなり動画ですが、こんな感じで動きます。英語で話かけると、リクエストを解釈して実行してくれたり、音声で応答してくれて面白いです。

&lt;div style=&#34;position: relative; padding-bottom: 56.25%; padding-top: 30px; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//www.youtube.com/embed/fWubPL5_YaU&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%;&#34; allowfullscreen frameborder=&#34;0&#34;&gt;&lt;/iframe&gt;
 &lt;/div&gt;
&lt;/p&gt;

&lt;h2 id=&#34;用意したもの&#34;&gt;用意したもの&lt;/h2&gt;

&lt;p&gt;音声入力にUSBマイクロフォンが必要なので、Raspberry Pi 3と併せて購入。他はありあわせで用意しました。&lt;br /&gt;
Raspberry Pi用のディスプレイを用意してもよいですが、今回はVNC server (Linux版リモートデスクトップ) を使います。&lt;/p&gt;

&lt;h3 id=&#34;買ったもの&#34;&gt;買ったもの&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Raspberry Pi 3 (4,800円)

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.amazon.co.jp/gp/product/B01D1FR2WE/&#34;&gt;https://www.amazon.co.jp/gp/product/B01D1FR2WE/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;USBマイクロフォン (1,600円)

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.amazon.co.jp/gp/product/B0027WPY82&#34;&gt;https://www.amazon.co.jp/gp/product/B0027WPY82&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;ありあわせ&#34;&gt;ありあわせ&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Micro SDカード

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.amazon.co.jp/dp/B00CDJNOX6/&#34;&gt;https://www.amazon.co.jp/dp/B00CDJNOX6/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Micro-USB (A-MicroB) ケーブル&lt;/li&gt;
&lt;li&gt;スピーカー&lt;/li&gt;
&lt;li&gt;LANケーブル&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;raspberry-pi-を起動する&#34;&gt;Raspberry Pi を起動する&lt;/h2&gt;

&lt;h3 id=&#34;osイメージの準備&#34;&gt;OSイメージの準備&lt;/h3&gt;

&lt;p&gt;以下の記事を参考に進めました。&lt;br /&gt;
&lt;a href=&#34;http://qiita.com/onlyindreams/items/acc70807b69b43e176bf&#34;&gt;Raspberry Pi 3にRaspbianをインストール(Mac OS X を使用)&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Rasbian Jessie は &lt;code&gt;2016-05-27&lt;/code&gt; リリースのものを用いました。&lt;/li&gt;
&lt;li&gt;ddコマンドのオプションで、ブロックサイズを大文字 (&lt;code&gt;bs=1M&lt;/code&gt;) で指定&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;起動手順&#34;&gt;起動手順&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;MicroSD、LAN、 USBマイクロフォン、スピーカーを接続しておきます。&lt;/li&gt;
&lt;li&gt;電源用としてUSBケーブルを挿すとBIOSが起動します。今回はOSであるRaspbian Jessieも自動で起動しました。&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;必要なライブラリをインストール&#34;&gt;必要なライブラリをインストール&lt;/h2&gt;

&lt;p&gt;AVSを利用するために必要なものを諸々インストールします。&lt;/p&gt;

&lt;h3 id=&#34;vnc-serverのインストール&#34;&gt;VNC Serverのインストール&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# install
sudo apt-get install tightvncserver
# run
tightvncserver
# auto run setup
vi /home/pi/.config/tightvnc.desktop
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;tightvnc.desktop&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;[Desktop Entry]
Type=Application
Name=TightVNC
Exec=vncserver :1
StartupNotify=false
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;vlcのインストール&#34;&gt;VLCのインストール&lt;/h3&gt;

&lt;p&gt;VLC media playerをインストールします。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# install
sudo apt-get install vlc-nox vlc-data
# add env vars
echo &amp;quot;export LD_LIBRARY_PATH=/usr/lib/vlc&amp;quot; &amp;gt;&amp;gt; ~/.bashrc
echo &amp;quot;export VLC_PLUGIN_PATH=/usr/lib/vlc/plugins&amp;quot; &amp;gt;&amp;gt; ~/.bashrc
soure ~/.bashrc
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;nodeとnpmのインストール&#34;&gt;NodeとNPMのインストール&lt;/h3&gt;

&lt;p&gt;後に出てくるサーバーの起動に必要なNodeとNPMをインストールします。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# apt-get update &amp;amp; upgrade. It takes about 15 min.
sudo apt-get update &amp;amp;&amp;amp; sudo apt-get upgrade
# install nodejs
curl -sL https://deb.nodesource.com/setup | sudo bash -
sudo apt-get install nodejs
cd /home/pi/Desktop/alexa-avs-raspberry-pi-master/samples/companionService
npm install
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;jdkとmavenのインストール&#34;&gt;JDKとMavenのインストール&lt;/h3&gt;

&lt;p&gt;公式DocはMavenの環境変数は &lt;code&gt;/etc/profile.d/maven.sh&lt;/code&gt; に追加する方法ですが、うまくいかなかったので手っ取り早く &lt;code&gt;bashrc&lt;/code&gt; に追加して進めました。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# java
cd /home/pi/Desktop/alexa-avs-raspberry-pi-master/samples/javaclient
./install-java8.sh
# maven
wget http://apache.osuosl.org/maven/maven-3/3.3.9/binaries/apache-maven-3.3.9-bin.tar.gz
sudo tar xvf apache-maven-3.3.9-bin.tar.gz  -C /opt
# add maven_vars
echo &amp;quot;export M2_HOME=/opt/apache-maven-3.3.9&amp;quot; &amp;gt;&amp;gt; ~/.bashrc
echo &amp;quot;export PATH=$PATH:$M2_HOME/bin&amp;quot; &amp;gt;&amp;gt; ~/.bashrc
source ~/.bashrc
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;証明書生成スクリプトを実行&#34;&gt;証明書生成スクリプトを実行&lt;/h3&gt;

&lt;p&gt;プロダクトID、シリアル番号、パスワードの3つを入力します。今回はパスワードは空のままで進めます。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;/home/pi/Desktop/alexa-avs-raspberry-pi-master/samples/javaclient/generate.sh
&amp;gt; product ID: my_device
&amp;gt; Serial Number: 123456
&amp;gt; Password: [blank]
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;クライアントidとclientsecretを発行&#34;&gt;クライアントIDとClientSecretを発行&lt;/h3&gt;

&lt;p&gt;ここは &lt;a href=&#34;https://github.com/amzn/alexa-avs-raspberry-pi#user-content-6---getting-started-with-alexa-voice-service&#34;&gt;公式Doc&lt;/a&gt; の画像のとおり進めればよいです。&lt;/p&gt;

&lt;h3 id=&#34;サーバとクライアントを起動&#34;&gt;サーバとクライアントを起動&lt;/h3&gt;

&lt;p&gt;下記のとおりサーバを起動します。 &lt;code&gt;config.js&lt;/code&gt; には先ほど発行したクライアントIDとClientSecretを入力しておきます。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# setup clientId and ClientSecret
vi /home/pi/Desktop/alexa-avs-raspberry-pi-master/samples/companionService/config.js
cd /home/pi/Desktop/alexa-avs-raspberry-pi-master/samples/companionService
npm start
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;続いてクライアントも起動します。起動するとGUIも一緒に立ち上がります。 &lt;code&gt;DISPLAY=:1.0&lt;/code&gt; はVNC経由の場合の指定です。外部ディスプレイを使う場合は &lt;code&gt;DISPLAY=:0.0&lt;/code&gt; です。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;cd /home/pi/Desktop/alexa-avs-raspberry-pi-master/samples/javaclient
mvn install
export DISPLAY=:1.0
mvn exec:exec
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;GUIに出てくるURLにアクセスしてデバイスの登録になります。ここも &lt;a href=&#34;https://github.com/amzn/alexa-avs-raspberry-pi#user-content-10---obtain-authorization-from-login-with-amazon&#34;&gt;公式Doc&lt;/a&gt; の画像のとおりです。以上が終わると、AVSを利用できます。&lt;/p&gt;

&lt;h2 id=&#34;次回予告&#34;&gt;次回予告&lt;/h2&gt;

&lt;p&gt;次回はAlexa Skillsを登録して使ってみようと思います。乞うご期待。Don&amp;rsquo;t miss out!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>音声は新しいパラダイムシフトになる 〜2016年度版メアリー・ミーカー氏レポートまとめ〜</title>
      <link>http://blog.algolab.jp/post/2016/07/29/mary-meeker-2016/</link>
      <pubDate>Fri, 29 Jul 2016 11:47:41 +0900</pubDate>
      
      <guid>http://blog.algolab.jp/post/2016/07/29/mary-meeker-2016/</guid>
      <description>

&lt;iframe src=&#34;//www.slideshare.net/slideshow/embed_code/key/D0N5V1PjTsIasR&#34; class=&#34;slideshare&#34; width=&#34;595&#34; height=&#34;485&#34; frameborder=&#34;0&#34; marginwidth=&#34;0&#34; marginheight=&#34;0&#34; scrolling=&#34;no&#34; style=&#34;border:1px solid #CCC; border-width:1px; margin-bottom:5px; max-width: 100%;&#34; allowfullscreen&gt; &lt;/iframe&gt;


&lt;p&gt;&lt;strong&gt;「音声インターフェースは新しいパラダイムシフトになる」&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;伝説のアナリスト、メアリー・ミーカー氏は、 &lt;a href=&#34;http://www.kpcb.com/internet-trends&#34;&gt;インターネット・トレンド&lt;/a&gt; 2016年度版の中で述べています。&lt;br /&gt;
ここでは、レポートの中から、音声に関するものをまとめていきます。&lt;/p&gt;

&lt;h2 id=&#34;インターフェースの技術革新は10年毎に起きる&#34;&gt;インターフェースの技術革新は10年毎に起きる&lt;/h2&gt;

&lt;figure&gt;
  &lt;img src=&#34;http://blog.algolab.jp/images//post/2016/07/29/mary-meeker-2016//114.jpg&#34;/&gt;
  
&lt;/figure&gt;


&lt;p&gt;ヒューマンインターフェースの歴史を振り返ってみると、ここ半世紀においては10年単位で技術革新が起きていることが分かります。&lt;br /&gt;
iPhoneによる、タッチ + カメラインターフェースが登場したのが 2007年。&lt;br /&gt;
次の10年では、SiriやAmazon Echoに代表される音声インターフェースが技術革新を起こすだろう、と予測しています。&lt;/p&gt;

&lt;h2 id=&#34;音声は最も効率の良い入力方法である&#34;&gt;音声は最も効率の良い入力方法である&lt;/h2&gt;

&lt;figure&gt;
  &lt;img src=&#34;http://blog.algolab.jp/images//post/2016/07/29/mary-meeker-2016//116.jpg&#34;/&gt;
  
&lt;/figure&gt;


&lt;p&gt;なぜ音声か、という問いに対して、メリットと独自性の観点から理由を述べています。&lt;br /&gt;
何より、「早い」「簡単」というのが音声インターフェースのメリットでしょう。&lt;br /&gt;
また、煩雑なGUIを必要とせず、低コストで場所をとらないことから、IoTとも相性が良い、としています。&lt;/p&gt;

&lt;h2 id=&#34;音声認識は人間並みに進歩&#34;&gt;音声認識は人間並みに進歩&lt;/h2&gt;

&lt;figure&gt;
  &lt;img src=&#34;http://blog.algolab.jp/images//post/2016/07/29/mary-meeker-2016//118.jpg&#34;/&gt;
  
&lt;/figure&gt;


&lt;p&gt;Googleの研究成果によると、語彙数、認識精度ともに年々向上しています。&lt;/p&gt;

&lt;h2 id=&#34;特に-認識精度はここ数年で急激に向上&#34;&gt;特に、認識精度はここ数年で急激に向上&lt;/h2&gt;

&lt;figure&gt;
  &lt;img src=&#34;http://blog.algolab.jp/images//post/2016/07/29/mary-meeker-2016//119.jpg&#34;/&gt;
  
&lt;/figure&gt;


&lt;p&gt;数年前までは良くて80%程度だったものが、最近は90%を優に超えてきているのが分かります。&lt;br /&gt;
人工知能研究の権威である、BaiduのAndrew Ng氏は、精度が 99% を超えるとゲームチェンジャーになる (= 世界が変わる) と述べています。&lt;br /&gt;
技術進歩の鍵となるのはディープラーニングで、音声認識分野においては、Baiduが一歩リードしている印象です。&lt;br /&gt;
Baidu の論文については、下記の記事内でも取り上げていますのでご参照ください。&lt;br /&gt;
&lt;a href=&#34;http://blog.algolab.jp/post/2016/07/21/icml-2016-reading/#deep-speech-2-end-to-end-speech-recognition-in-english-and-mandarin&#34;&gt;ICML2016読み会 まとめ&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;音声アシスタントの利用は技術の進歩が牽引&#34;&gt;音声アシスタントの利用は技術の進歩が牽引&lt;/h2&gt;

&lt;figure&gt;
  &lt;img src=&#34;http://blog.algolab.jp/images//post/2016/07/29/mary-meeker-2016//121.jpg&#34;/&gt;
  
&lt;/figure&gt;


&lt;p&gt;入力インターフェースがキーボードから音声に置き換わるのはまだ少し早いと前置きをしながら、利用状況についてまとめています。&lt;br /&gt;
音声アシスタントの利用者は2015年時点で65%で、使い始めるきっかけとしては、ソフトウェア技術の進歩の理由が一番とのことです。&lt;/p&gt;

&lt;h2 id=&#34;音声検索の利用は開始時点の35倍に&#34;&gt;音声検索の利用は開始時点の35倍に&lt;/h2&gt;

&lt;figure&gt;
  &lt;img src=&#34;http://blog.algolab.jp/images//post/2016/07/29/mary-meeker-2016//122.jpg&#34;/&gt;
  
&lt;/figure&gt;


&lt;p&gt;iPhoneおよびGoogleが音声検索を開始したのが2008年ですが、その時に比べ、利用回数は右肩あがりに伸びています。&lt;/p&gt;

&lt;h2 id=&#34;タイピングが難しい中国語ではさらに伸長&#34;&gt;タイピングが難しい中国語ではさらに伸長&lt;/h2&gt;

&lt;figure&gt;
  &lt;img src=&#34;http://blog.algolab.jp/images//post/2016/07/29/mary-meeker-2016//123.jpg&#34;/&gt;
  
&lt;/figure&gt;


&lt;p&gt;Baiduの利用状況を見ると、音声入力、音声読み上げともに伸びています。&lt;br /&gt;
スマートフォンにおける言語のタイピングのしやすさ、も音声入力への利用へ影響を与えそうです。&lt;/p&gt;

&lt;h2 id=&#34;1日に6-8回音声検索する&#34;&gt;1日に6-8回音声検索する&lt;/h2&gt;

&lt;figure&gt;
  &lt;img src=&#34;http://blog.algolab.jp/images//post/2016/07/29/mary-meeker-2016//124.jpg&#34;/&gt;
  
&lt;/figure&gt;


&lt;p&gt;&lt;a href=&#34;http://www.soundhound.com/hound&#34;&gt;Hound&lt;/a&gt; (音声アシスタントアプリ) のデータによると、1日で6-8回音声検索を行うようです。&lt;br /&gt;
カテゴリとしては、「一般情報」「エンターテイメント」「地域情報」「アシスタント」の4つにまたがる、とのことです。&lt;/p&gt;

&lt;h2 id=&#34;2020年には音声検索が50-を超える&#34;&gt;2020年には音声検索が50%を超える&lt;/h2&gt;

&lt;figure&gt;
  &lt;img src=&#34;http://blog.algolab.jp/images//post/2016/07/29/mary-meeker-2016//125.jpg&#34;/&gt;
  
&lt;/figure&gt;


&lt;p&gt;音声検索の利用について、過去、現在、未来をまとめています。&lt;br /&gt;
Adrew Ng氏は、2020年には検索の半分以上が音声か画像になる、と予測しています。&lt;/p&gt;

&lt;h2 id=&#34;ハンズフリー-画面フリー&#34;&gt;ハンズフリー &amp;amp; 画面フリー&lt;/h2&gt;

&lt;figure&gt;
  &lt;img src=&#34;http://blog.algolab.jp/images//post/2016/07/29/mary-meeker-2016//127.jpg&#34;/&gt;
  
&lt;/figure&gt;


&lt;p&gt;音声インターフェースを使う理由のトップが、「手 (もしくは画面) がふさがっている時に便利だから」で、&lt;br /&gt;
利用シチュエーションとしては、「家」「車」「移動中」が大部分を占めています。&lt;/p&gt;

&lt;h2 id=&#34;プラットフォームは構築され-サードパーティの動きも速い&#34;&gt;プラットフォームは構築され、サードパーティの動きも速い&lt;/h2&gt;

&lt;figure&gt;
  &lt;img src=&#34;http://blog.algolab.jp/images//post/2016/07/29/mary-meeker-2016//129.jpg&#34;/&gt;
  
&lt;/figure&gt;


&lt;p&gt;前のスライドで述べた「家」「車」「移動中」において、Amazon Alexaは様々なOEMを提供しています。&lt;br /&gt;
また、Alexaを拡張できるAlexa Skills Kitの開発も盛んになっています。&lt;/p&gt;

&lt;h2 id=&#34;ショッピングも迅速に&#34;&gt;ショッピングも迅速に&lt;/h2&gt;

&lt;figure&gt;
  &lt;img src=&#34;http://blog.algolab.jp/images//post/2016/07/29/mary-meeker-2016//130.jpg&#34;/&gt;
  
&lt;/figure&gt;


&lt;p&gt;Amazonは、ショッピングをモバイルアプリから音声入力へ置き換えることを目指しています。&lt;/p&gt;

&lt;h2 id=&#34;amazon-echoの所有率は5&#34;&gt;Amazon Echoの所有率は5%&lt;/h2&gt;

&lt;figure&gt;
  &lt;img src=&#34;http://blog.algolab.jp/images//post/2016/07/29/mary-meeker-2016//131.jpg&#34;/&gt;
  
&lt;/figure&gt;


&lt;p&gt;CIRPによると、AmazonEchoの所有者は5%で、認知度は61%とのことです。&lt;/p&gt;

&lt;h2 id=&#34;2016年は産業の変わり目となる&#34;&gt;2016年は産業の変わり目となる&lt;/h2&gt;

&lt;figure&gt;
  &lt;img src=&#34;http://blog.algolab.jp/images//post/2016/07/29/mary-meeker-2016//133.jpg&#34;/&gt;
  
&lt;/figure&gt;


&lt;p&gt;コンピュータ産業の変わり目は後から振り返ると明確なものであると前置きした上で、iPhoneの売上が2015年にピークを迎えたことを分岐点と捉え、今後はAmazon Echoの売上が急激に伸びるのではないか、と締めくくっています。&lt;/p&gt;

&lt;h2 id=&#34;おわりに&#34;&gt;おわりに&lt;/h2&gt;

&lt;p&gt;まとめは以上となります。&lt;br /&gt;
未来を見据えたときに、やはり「音声」は外せないキーワードとなってくるのではないでしょうか。&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>